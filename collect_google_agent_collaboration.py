import os
import json
import asyncio
from pathlib import Path
import httpx
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

# Data for SEOè¨­å®š
BASE = os.getenv("DATAFORSEO_BASE", "https://api.dataforseo.com/v3").rstrip("/")
LOGIN = os.getenv("DATAFORSEO_LOGIN")
PASSWORD = os.getenv("DATAFORSEO_PASSWORD")
LANG = os.getenv("DATAFORSEO_LANGUAGE_CODE", "ja")
LOC = int(os.getenv("DATAFORSEO_LOCATION_CODE", "2392"))  # Japan

class AgentCollaborationGoogleCollector:
    def __init__(self):
        self.client = None
        self.all_keywords = set()
        
    async def __aenter__(self):
        self.client = httpx.AsyncClient(
            auth=(LOGIN, PASSWORD),
            headers={"Content-Type": "application/json"},
            timeout=60
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            await self.client.aclose()
    
    async def check_connection(self):
        """æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            r = await self.client.get(f"{BASE}/appendix/user_data", timeout=30)
            j = r.json()
            if j.get("status_code") == 20000:
                print("âœ… Data for SEOæ¥ç¶šæˆåŠŸ")
                return True
            else:
                print(f"âŒ æ¥ç¶šå¤±æ•—: {j.get('status_message')}")
                return False
        except Exception as e:
            print(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def get_main_keyword_data(self, keyword):
        """ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAã‚’å–å¾—ï¼ˆ1å›ç›®ã®APIå‘¼ã³å‡ºã—ï¼‰"""
        print(f"ğŸš€ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã‹ã‚‰Related Searches + PAAå–å¾—ä¸­...")
        
        task = {
            "language_code": LANG,
            "location_code": LOC,
            "keyword": keyword,
            "depth": 2,
            "include_serp_info": True
        }
        
        try:
            r = await self.client.post(
                f"{BASE}/serp/google/organic/live/advanced",
                json=[task]
            )
            j = r.json()
            
            related_searches = []
            paa_questions = []
            
            for t in j.get("tasks", []):
                for res in t.get("result", []):
                    # Related Searches
                    for item in res.get("items", []):
                        if item.get("type") == "related_searches":
                            for rel_item in item.get("items", []):
                                suggestion = rel_item.get("text") or rel_item.get("suggestion")
                                if suggestion:
                                    related_searches.append(suggestion)
                    
                    # People Also Ask
                    for item in res.get("items", []):
                        if item.get("type") == "people_also_ask":
                            for paa_item in item.get("items", []):
                                question = paa_item.get("question")
                                if question:
                                    paa_questions.append(question)
            
            # é‡è¤‡é™¤å»
            all_suggestions = related_searches + paa_questions
            unique_suggestions = list(dict.fromkeys(all_suggestions))
            
            print(f"âœ… ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—å®Œäº†:")
            print(f"   - Related Searches: {len(related_searches)}ä»¶")
            print(f"   - People Also Ask: {len(paa_questions)}ä»¶")
            print(f"   - ç·ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {len(unique_suggestions)}ä»¶")
            
            self.all_keywords.update(unique_suggestions)
            return unique_suggestions
            
        except Exception as e:
            print(f"    âš ï¸ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def create_agent_analysis_file(self, keywords, main_keyword):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        filename = f"agent_analysis_{main_keyword.replace(' ', '_')}.txt"
        
        content = f"""=== ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æä¾é ¼ ===

ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {main_keyword}

ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã€SEOä¸Šæœ‰ç”¨ãªä¸Šä½5å€‹ã‚’é¸å®šã—ã¦ãã ã•ã„ã€‚

é¸å®šåŸºæº–ï¼š
- ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨é–¢é€£æ€§ãŒã‚ã‚‹
- æ¤œç´¢ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆã«ä½¿ãˆãã†
- å­£ç¯€æ€§ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ€§ãŒé«˜ã„

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§ï¼ˆ{len(keywords)}ä»¶ï¼‰ï¼š
{chr(10).join(f"{i+1:2d}. {kw}" for i, kw in enumerate(keywords))}

=== åˆ†æçµæœ ===
é¸å®šã•ã‚ŒãŸä¸Šä½5å€‹ï¼š
1. 
2. 
3. 
4. 
5. 

é¸å®šç†ç”±ï¼š
"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"\nğŸ“‹ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {filename}")
        print("ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€ä¿¡ã—ã¦åˆ†æã—ã¦ãã ã•ã„")
        print("ğŸ“ åˆ†æçµæœã‚’å…¥åŠ›ã—ã¦Enterã‚’æŠ¼ã—ã¦ãã ã•ã„")
        
        return filename
    
    def get_agent_selection(self, filename):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸å®šçµæœã‚’å–å¾—"""
        print(f"\nğŸ“¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸å®šçµæœã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        print("ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ« {filename} ã®åˆ†æçµæœã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„")
        
        selected_keywords = []
        for i in range(5):
            while True:
                try:
                    kw = input(f"é¸å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ {i+1}: ").strip()
                    if kw:
                        selected_keywords.append(kw)
                        break
                    else:
                        print("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                except KeyboardInterrupt:
                    print("\nâŒ å…¥åŠ›ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                    return []
        
        print(f"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸å®šå®Œäº†: {len(selected_keywords)}ä»¶")
        for i, kw in enumerate(selected_keywords, 1):
            print(f"  {i}. {kw}")
        
        return selected_keywords
    
    async def get_selected_keywords_data(self, selected_keywords):
        """é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAã‚’å–å¾—ï¼ˆ2å›ç›®ã®APIå‘¼ã³å‡ºã—ï¼‰"""
        print(f"\nğŸ” é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{len(selected_keywords)}ä»¶ã‹ã‚‰Related Searches + PAAå–å¾—ä¸­...")
        
        # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ã‚¿ã‚¹ã‚¯é…åˆ—
        batch_tasks = []
        for keyword in selected_keywords:
            task = {
                "language_code": LANG,
                "location_code": LOC,
                "keyword": keyword,
                "depth": 2,
                "include_serp_info": True
            }
            batch_tasks.append(task)
        
        print(f"   ğŸ“ {len(selected_keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒƒãƒå‡¦ç†")
        
        try:
            r = await self.client.post(
                f"{BASE}/serp/google/organic/live/advanced",
                json=batch_tasks
            )
            j = r.json()
            
            all_new_suggestions = []
            keyword_results = {}
            
            for i, task_result in enumerate(j.get("tasks", [])):
                keyword = selected_keywords[i]
                related_searches = []
                paa_questions = []
                
                for res in task_result.get("result", []):
                    # Related Searches
                    for item in res.get("items", []):
                        if item.get("type") == "related_searches":
                            for rel_item in item.get("items", []):
                                suggestion = rel_item.get("text") or rel_item.get("suggestion")
                                if suggestion:
                                    related_searches.append(suggestion)
                    
                    # People Also Ask
                    for item in res.get("items", []):
                        if item.get("type") == "people_also_ask":
                            for paa_item in item.get("items", []):
                                question = paa_item.get("question")
                                if question:
                                    paa_questions.append(question)
                
                keyword_results[keyword] = {
                    "related_searches": related_searches,
                    "paa_questions": paa_questions
                }
                
                all_new_suggestions.extend(related_searches + paa_questions)
                print(f"  ğŸ“ {keyword}: Related {len(related_searches)}ä»¶, PAA {len(paa_questions)}ä»¶")
            
            # é‡è¤‡é™¤å»
            unique_new_suggestions = []
            for suggestion in all_new_suggestions:
                if suggestion not in self.all_keywords:
                    unique_new_suggestions.append(suggestion)
                    self.all_keywords.add(suggestion)
            
            print(f"âœ… é¸å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—å®Œäº†: {len(unique_new_suggestions)}ä»¶ã®æ–°è¦ã‚µã‚¸ã‚§ã‚¹ãƒˆ")
            return unique_new_suggestions, keyword_results
            
        except Exception as e:
            print(f"    âš ï¸ é¸å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return [], {}
    
    async def run_agent_collaboration_collection(self, seed_keyword, target_count=100):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€£æºã«ã‚ˆã‚‹ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ï¼ˆ2å›ã®APIå‘¼ã³å‡ºã—ï¼‰"""
        print(f"ğŸš€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€£æºGoogleã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†é–‹å§‹: ã€Œ{seed_keyword}ã€")
        print(f"ğŸ¯ ç›®æ¨™: {target_count}ä»¶")
        print(f"ğŸ’¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨é€£æºã—ã¦åŠ¹ç‡çš„ã«åé›†")
        
        # æ¥ç¶šç¢ºèª
        if not await self.check_connection():
            return None
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAå–å¾—ï¼ˆ1å›ç›®ã®APIå‘¼ã³å‡ºã—ï¼‰
        main_suggestions = await self.get_main_keyword_data(seed_keyword)
        
        if len(main_suggestions) == 0:
            print("âŒ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚µã‚¸ã‚§ã‚¹ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        print(f"\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1çµæœ: {len(main_suggestions)}ä»¶ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        analysis_file = self.create_agent_analysis_file(main_suggestions, seed_keyword)
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸å®šçµæœã‚’å–å¾—
        selected_keywords = self.get_agent_selection(analysis_file)
        
        if len(selected_keywords) == 0:
            print("âŒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸å®šãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰è¿½åŠ å–å¾—ï¼ˆ2å›ç›®ã®APIå‘¼ã³å‡ºã—ï¼‰
        expanded_suggestions, keyword_results = await self.get_selected_keywords_data(selected_keywords)
        
        # æœ€çµ‚çµæœ
        final_keywords = list(self.all_keywords)[:target_count]
        
        # ã‚³ã‚¹ãƒˆè¨ˆç®—
        total_api_calls = 2  # 1å›ç›® + 2å›ç›®
        estimated_cost = total_api_calls * 0.02  # $0.02/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        
        print(f"\nğŸ‰ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€£æºåé›†å®Œäº†!")
        print(f"ğŸ“Š æœ€çµ‚çµæœ: {len(final_keywords)}ä»¶")
        print(f"   - ãƒ¡ã‚¤ãƒ³ã‚µã‚¸ã‚§ã‚¹ãƒˆ: {len(main_suggestions)}ä»¶")
        print(f"   - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸å®š: {len(selected_keywords)}ä»¶")
        print(f"   - æ‹¡å¼µã‚µã‚¸ã‚§ã‚¹ãƒˆ: {len(expanded_suggestions)}ä»¶")
        print(f"   - ç·ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {len(self.all_keywords)}ä»¶")
        print(f"ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æ:")
        print(f"   - APIå‘¼ã³å‡ºã—å›æ•°: {total_api_calls}å›")
        print(f"   - æ¨å®šã‚³ã‚¹ãƒˆ: ${estimated_cost:.2f} (ç´„{estimated_cost*150:.0f}å††)")
        print(f"   - å¾“æ¥æ–¹å¼ã¨ã®æ¯”è¼ƒ: ç´„{(1 - total_api_calls/19)*100:.0f}%ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›")
        
        return {
            "seed": seed_keyword,
            "total_collected": len(final_keywords),
            "keywords": final_keywords,
            "raw_data": {
                "main_suggestions": main_suggestions,
                "selected_keywords": selected_keywords,
                "expanded_suggestions": expanded_suggestions,
                "keyword_results": keyword_results
            },
            "cost_analysis": {
                "total_api_calls": total_api_calls,
                "estimated_cost_usd": estimated_cost,
                "estimated_cost_jpy": estimated_cost * 150,
                "cost_reduction_percent": (1 - total_api_calls/19)*100
            },
            "breakdown": {
                "main_suggestions": len(main_suggestions),
                "selected_keywords": len(selected_keywords),
                "expanded_suggestions": len(expanded_suggestions),
                "total_unique": len(self.all_keywords)
            }
        }

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if not LOGIN or not PASSWORD:
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—
    import sys
    seed_keyword = sys.argv[1] if len(sys.argv) > 1 else "å¤ ãŠã™ã™ã‚ ãŠé…’"
    target_count = int(sys.argv[2]) if len(sys.argv) > 2 else 100
    
    print(f"ğŸŒ± ã‚·ãƒ¼ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {seed_keyword}")
    print(f"ğŸ¯ ç›®æ¨™ä»¶æ•°: {target_count}ä»¶")
    
    async with AgentCollaborationGoogleCollector() as collector:
        result = await collector.run_agent_collaboration_collection(seed_keyword, target_count)
        
        if result:
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_file = f"agent_collaboration_{seed_keyword.replace(' ', '_')}_{len(result['keywords'])}ä»¶.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ä¸Šä½30ä»¶ã‚’è¡¨ç¤º
            print(f"\nğŸ“‹ ä¸Šä½30ä»¶:")
            for i, kw in enumerate(result['keywords'][:30], 1):
                print(f"  {i:2d}. {kw}")

if __name__ == "__main__":
    asyncio.run(main())
