#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google SERP APIã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰å¤§é‡ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆãƒ»é–¢é€£è³ªå•ãƒ»AIæ¦‚è¦ã‚’å–å¾—
ç›®æ¨™: 200ä»¶ä»¥ä¸Šã®ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—ã€APIå‘¼ã³å‡ºã—1å›ã®ã¿ï¼ˆã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼‰
"""

import asyncio
import httpx
import json
import os
from datetime import datetime
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

class GoogleSuggestionCollector:
    def __init__(self):
        """SERP APIã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–"""
        self.api_key = os.getenv('SERPAPI_API_KEY')
        if not self.api_key:
            raise ValueError("SERPAPI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.base_url = "https://serpapi.com/search.json"
        print("âœ… SERP APIã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
    async def get_serp_data(self, keyword: str) -> dict:
        """SERP APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆ1å›ã®å‘¼ã³å‡ºã—ã§æœ€å¤§é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼‰"""
        print(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã®SERPãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        params = {
            'engine': 'google',
            'q': keyword,
            'google_domain': 'google.com',
            'hl': 'ja',
            'gl': 'jp',
            'num': 100,  # æœ€å¤§100ä»¶ã®æ¤œç´¢çµæœ
            'start': 0,  # é–‹å§‹ä½ç½®
            'related_questions': 'true',  # é–¢é€£è³ªå•ã‚’æœ‰åŠ¹åŒ–
            'ai_overview': 'true',        # AIæ¦‚è¦ã‚’æœ‰åŠ¹åŒ–
            'featured_snippet': 'true',   # ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æœ‰åŠ¹åŒ–
            'people_also_ask': 'true',    # ã‚ˆãã‚ã‚‹è³ªå•ã‚’æœ‰åŠ¹åŒ–
            'related_searches': 'true',   # é–¢é€£æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–
            'knowledge_graph': 'true',    # ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’æœ‰åŠ¹åŒ–
            'api_key': self.api_key
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(self.base_url, params=params)
                response.raise_for_status()
                data = response.json()
                print(f"âœ… SERP APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸ")
                return data
                
        except httpx.TimeoutException:
            print("âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: SERP APIã®å¿œç­”ãŒé…ã™ãã¾ã™")
            raise
        except httpx.HTTPStatusError as e:
            print(f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code}")
            raise
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def extract_all_suggestions(self, serp_data: dict) -> list:
        """SERPãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å…¨ã¦ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆãƒ»é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º"""
        print("ğŸ“ SERPãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­...")
        suggestions = []
        
        # 1. åŸºæœ¬çš„ãªã‚µã‚¸ã‚§ã‚¹ãƒˆ
        if 'suggestions' in serp_data:
            suggestions.extend(serp_data['suggestions'])
            print(f"  ğŸ“Œ åŸºæœ¬ã‚µã‚¸ã‚§ã‚¹ãƒˆ: {len(serp_data['suggestions'])}ä»¶")
        
        # 2. æ¤œç´¢çµæœã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
        if 'organic_results' in serp_data:
            for result in serp_data['organic_results']:
                if 'title' in result:
                    suggestions.append(result['title'])
            print(f"  ğŸ“Œ æ¤œç´¢çµæœã‚¿ã‚¤ãƒˆãƒ«: {len(serp_data['organic_results'])}ä»¶")
        
        # 3. é–¢é€£æ¤œç´¢ã‚’æŠ½å‡º
        if 'related_searches' in serp_data:
            for search in serp_data['related_searches']:
                if isinstance(search, dict) and 'query' in search:
                    suggestions.append(search['query'])
                elif isinstance(search, str):
                    suggestions.append(search)
            print(f"  ğŸ“Œ é–¢é€£æ¤œç´¢: {len(serp_data['related_searches'])}ä»¶")
        
        # 4. Related Questionsï¼ˆé–¢é€£è³ªå•ï¼‰ã‚’æŠ½å‡º
        if 'related_questions' in serp_data:
            for question_data in serp_data['related_questions']:
                if isinstance(question_data, dict):
                    # è³ªå•æ–‡ã‚’æŠ½å‡º
                    if 'question' in question_data:
                        suggestions.append(question_data['question'])
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ã‚‚æƒ…å ±ã‚’æŠ½å‡º
                    if 'text_blocks' in question_data:
                        for block in question_data['text_blocks']:
                            if isinstance(block, dict):
                                # ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡º
                                if 'snippet' in block:
                                    suggestions.append(block['snippet'])
                                
                                # ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’æŠ½å‡º
                                if 'list' in block:
                                    for item in block['list']:
                                        if isinstance(item, dict):
                                            if 'title' in item:
                                                suggestions.append(item['title'])
                                            if 'snippet' in item:
                                                suggestions.append(item['snippet'])
            print(f"  ğŸ“Œ é–¢é€£è³ªå•: {len(serp_data['related_questions'])}ä»¶")
        
        # 5. People Also Askï¼ˆã‚ˆãã‚ã‚‹è³ªå•ï¼‰ã‚’æŠ½å‡º
        if 'people_also_ask' in serp_data:
            for paa in serp_data['people_also_ask']:
                if isinstance(paa, dict):
                    if 'question' in paa:
                        suggestions.append(paa['question'])
                    if 'answer' in paa:
                        suggestions.append(paa['answer'])
            print(f"  ğŸ“Œ ã‚ˆãã‚ã‚‹è³ªå•: {len(serp_data['people_also_ask'])}ä»¶")
        
        # 6. AIæ¦‚è¦ã‚’å¼·åŒ–ã—ã¦æŠ½å‡º
        if 'ai_overview' in serp_data:
            ai_overview = serp_data['ai_overview']
            ai_count = 0
            if isinstance(ai_overview, dict):
                # è³ªå•ã‚’æŠ½å‡º
                if 'questions' in ai_overview:
                    for q in ai_overview['questions']:
                        if isinstance(q, dict) and 'question' in q:
                            suggestions.append(q['question'])
                            ai_count += 1
                        elif isinstance(q, str):
                            suggestions.append(q)
                            ai_count += 1
                
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
                if 'text_blocks' in ai_overview:
                    for block in ai_overview['text_blocks']:
                        if isinstance(block, dict):
                            if 'snippet' in block:
                                suggestions.append(block['snippet'])
                                ai_count += 1
                            if 'title' in block:
                                suggestions.append(block['title'])
                                ai_count += 1
                
                # ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’æŠ½å‡º
                if 'list' in ai_overview:
                    for item in ai_overview['list']:
                        if isinstance(item, dict):
                            if 'title' in item:
                                suggestions.append(item['title'])
                                ai_count += 1
                            if 'snippet' in item:
                                suggestions.append(item['snippet'])
                                ai_count += 1
                
                # ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚ç¢ºèª
                for key, value in ai_overview.items():
                    if isinstance(value, str) and key not in ['questions', 'text_blocks', 'list']:
                        suggestions.append(value)
                        ai_count += 1
            
            print(f"  ğŸ“Œ AIæ¦‚è¦: {ai_count}ä»¶æŠ½å‡ºå®Œäº†")
        
        # 7. ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŠ½å‡º
        if 'featured_snippet' in serp_data:
            snippet = serp_data['featured_snippet']
            if isinstance(snippet, dict):
                if 'title' in snippet:
                    suggestions.append(snippet['title'])
                if 'snippet' in snippet:
                    suggestions.append(snippet['snippet'])
            print(f"  ğŸ“Œ ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: 1ä»¶")
        
        # 8. æ¤œç´¢çµæœã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å…¨ã¦æŠ½å‡ºï¼ˆæ–‡å­—æ•°åˆ¶é™ãªã—ï¼‰
        if 'organic_results' in serp_data:
            snippet_count = 0
            for result in serp_data['organic_results']:
                if 'snippet' in result:
                    snippet = result['snippet']
                    if isinstance(snippet, str):
                        # ã‚¹ãƒ‹ãƒšãƒƒãƒˆå…¨ä½“ã‚’è¿½åŠ ï¼ˆæ—¥æœ¬èªéƒ¨åˆ†ã®æŠ½å‡ºã¯å¾Œã§è¡Œã†ï¼‰
                        suggestions.append(snippet)
                        snippet_count += 1
                        
                        # æ—¥æœ¬èªéƒ¨åˆ†ã‚‚åˆ¥é€”æŠ½å‡º
                        japanese_text = self.extract_japanese_text(snippet)
                        if japanese_text and japanese_text != snippet:
                            suggestions.append(japanese_text)
            if snippet_count > 0:
                print(f"  ğŸ“Œ æ¤œç´¢çµæœã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {snippet_count}ä»¶ï¼ˆå…¨ä½“ + æ—¥æœ¬èªéƒ¨åˆ†ï¼‰")
        
        # é‡è¤‡ã‚’é™¤å»ã—ã¦è¿”ã™
        unique_suggestions = list(set(suggestions))
        
        # é•·æ–‡ã‚µã‚¸ã‚§ã‚¹ãƒˆã®èª¿æŸ»
        long_suggestions = [s for s in unique_suggestions if len(s) > 100]
        if long_suggestions:
            print(f"ğŸ” é•·æ–‡ã‚µã‚¸ã‚§ã‚¹ãƒˆï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰ã®èª¿æŸ»:")
            for i, long_s in enumerate(long_suggestions[:5], 1):  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                print(f"  {i}. é•·ã•: {len(long_s)}æ–‡å­—")
                print(f"     å†…å®¹: {long_s[:100]}...")
                print(f"     å‡ºæ‰€: {'AIæ¦‚è¦' if 'AIæ¦‚è¦' in str(serp_data.get('ai_overview', '')) else 'ãã®ä»–'}")
                print()
        
        # URLã‚’å«ã‚€ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’é™¤å»ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¯ä¿æŒï¼‰
        unique_suggestions = [s for s in unique_suggestions if not ('http://' in s or 'https://' in s or 'www.' in s)]
        
        # é•·ã™ãã‚‹ã‚µã‚¸ã‚§ã‚¹ãƒˆï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰ã‚’é™¤å»
        unique_suggestions = [s for s in unique_suggestions if len(s) <= 100]
        
        print(f"âœ… é‡è¤‡é™¤å»å®Œäº†: {len(suggestions)}ä»¶ â†’ {len(unique_suggestions)}ä»¶")
        print(f"âœ… é•·æ–‡é™¤å»å®Œäº†: 100æ–‡å­—ä»¥ä¸‹ã®ã¿æ®‹ã—ã¾ã—ãŸ")
        
        return unique_suggestions
    
    def extract_japanese_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥æœ¬èªéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºï¼ˆæ–‡å­—æ•°åˆ¶é™ãªã—ï¼‰"""
        if not text:
            return ""
        
        # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰ã‚’å«ã‚€éƒ¨åˆ†ã‚’æŠ½å‡º
        import re
        japanese_pattern = r'[ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]+'
        japanese_matches = re.findall(japanese_pattern, text)
        
        if japanese_matches:
            # æ—¥æœ¬èªéƒ¨åˆ†ã‚’çµåˆï¼ˆæ–‡å­—æ•°åˆ¶é™ã‚’å‰Šé™¤ï¼‰
            japanese_text = ''.join(japanese_matches)
            return japanese_text
        
        return ""
    
    async def collect_suggestions(self, keyword: str) -> dict:
        """ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’åé›†"""
        print(f"\nğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 60)
        
        try:
            # SERP APIã‚’1å›ã®ã¿å‘¼ã³å‡ºã—
            serp_data = await self.get_serp_data(keyword)
            
            # ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’æŠ½å‡º
            suggestions = self.extract_all_suggestions(serp_data)
            
            # çµæœã‚’æ•´ç†
            result = {
                "collection_method": "SERP APIæœ€é©åŒ–ç‰ˆï¼ˆå˜ä¸€èªç¾¤ï¼‰",
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
                "api_calls": 1,
                "main_keyword": keyword,
                "results": {
                    "total_unique": len(suggestions),
                    "suggestions": suggestions,
                    "serp_results": [{
                        "keyword": keyword,
                        "suggestions": suggestions,
                        "serp_data": serp_data
                    }]
                }
            }
            
            print(f"\nğŸ‰ åé›†å®Œäº†: {len(suggestions)}ä»¶ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆ")
            
            # ç›®æ¨™ä»¶æ•°ã¨ã®æ¯”è¼ƒ
            if len(suggestions) >= 100:
                print(f"ğŸ¯ ç›®æ¨™é”æˆï¼ 100ä»¶ä»¥ä¸Šï¼ˆ{len(suggestions)}ä»¶ï¼‰ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
            else:
                print(f"âš ï¸  ç›®æ¨™æœªé”: {len(suggestions)}ä»¶ï¼ˆç›®æ¨™: 100ä»¶ä»¥ä¸Šï¼‰")
            
            return result
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return None

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Google SERP API ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # çµæœç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
    results_dir = "serp_results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
        print(f"ğŸ“ çµæœç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {results_dir}")
    
    # ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®š
    main_keyword = "å¤ã€€ãŠã™ã™ã‚ã€€é…’"
    
    try:
        # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
        collector = GoogleSuggestionCollector()
        
        # ã‚µã‚¸ã‚§ã‚¹ãƒˆã‚’åé›†
        result = await collector.collect_suggestions(main_keyword)
        
        if result:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"serp_collected_{len(result['results']['suggestions'])}ä»¶.json"
            filepath = os.path.join(results_dir, filename)
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ“ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            print(f"ğŸ“Š å–å¾—ä»¶æ•°: {len(result['results']['suggestions'])}ä»¶")
            
            # æœ€åˆã®10ä»¶ã‚’è¡¨ç¤º
            print("\nğŸ“ å–å¾—ã•ã‚ŒãŸã‚µã‚¸ã‚§ã‚¹ãƒˆï¼ˆæœ€åˆã®10ä»¶ï¼‰:")
            for i, suggestion in enumerate(result['results']['suggestions'][:10], 1):
                print(f"{i:2d}. {suggestion}")
            
            if len(result['results']['suggestions']) > 10:
                print(f"... ä»– {len(result['results']['suggestions']) - 10}ä»¶")
            
            # çµ±è¨ˆæƒ…å ±
            print(f"\nğŸ“ˆ çµ±è¨ˆæƒ…å ±:")
            print(f"  - APIå‘¼ã³å‡ºã—å›æ•°: {result['api_calls']}å›")
            print(f"  - é‡è¤‡é™¤å»å¾Œã®ä»¶æ•°: {result['results']['total_unique']}ä»¶")
            print(f"  - å‡¦ç†æ™‚åˆ»: {result['timestamp']}")
            print(f"  - ä¿å­˜å…ˆ: {results_dir}/")
            
            # SERP APIã‚³ã‚¹ãƒˆæƒ…å ±
            print(f"\nğŸ’° SERP APIã‚³ã‚¹ãƒˆæƒ…å ±:")
            print(f"  - åŸºæœ¬æ–™é‡‘: $0.05/æ¤œç´¢")
            print(f"  - ä»Šå›ã®æ–™é‡‘: ${0.05 * result['api_calls']:.2f}")
            print(f"  - 1ä»¶ã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆ: ${(0.05 * result['api_calls']) / result['results']['total_unique']:.4f}")
            print(f"  - ã‚³ã‚¹ãƒˆåŠ¹ç‡: 1å›ã®APIå‘¼ã³å‡ºã—ã§{result['results']['total_unique']}ä»¶å–å¾—")
            
        else:
            print("âŒ ã‚µã‚¸ã‚§ã‚¹ãƒˆã®åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
