#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Data for SEOã‚’ä½¿ç”¨ã—ãŸGoogleã‚µã‚¸ã‚§ã‚¹ãƒˆåé›† - å…¨è‡ªå‹•ç‰ˆ
ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•é¸å®šã—ã€APIå‘¼ã³å‡ºã—ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹
"""

import asyncio
import httpx
import json
import os
from datetime import datetime
from typing import List, Dict, Any, Tuple
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
from pathlib import Path
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

class GoogleSuggestionCollector:
    def __init__(self):
        self.login = os.getenv('DATAFORSEO_LOGIN')
        self.password = os.getenv('DATAFORSEO_PASSWORD')
        self.language_code = os.getenv('DATAFORSEO_LANGUAGE_CODE', 'ja')  # æ—¥æœ¬èª
        self.location_code = int(os.getenv('DATAFORSEO_LOCATION_CODE', '2392'))  # æ—¥æœ¬
        
        if not self.login or not self.password:
            raise ValueError("DATAFORSEO_LOGIN ã¾ãŸã¯ DATAFORSEO_PASSWORD ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.base_url = "https://api.dataforseo.com/v3"
        self.collected_keywords = set()
        
    async def get_autocomplete_batch(self, keyword: str) -> List[str]:
        """è¤‡æ•°ã®ã‚«ãƒ¼ã‚½ãƒ«ã§Google Autocompleteã‚’å–å¾—"""
        print(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã®Autocompleteå–å¾—ä¸­...")
        
        # ã‚ˆã‚Šå¤šãã®ã‚«ãƒ¼ã‚½ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚µã‚¸ã‚§ã‚¹ãƒˆæ•°ã‚’å¢—ã‚„ã™
        cursors = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
        all_suggestions = []
        
        async with httpx.AsyncClient(timeout=120) as client:
            tasks = []
            for cursor in cursors:
                task = self._get_autocomplete_single(client, keyword, cursor)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    print(f"âš ï¸ ã‚«ãƒ¼ã‚½ãƒ« {cursors[i]} ã§ã‚¨ãƒ©ãƒ¼: {result}")
                elif result:
                    all_suggestions.extend(result)
        
        # é‡è¤‡é™¤å»
        unique_suggestions = list(set(all_suggestions))
        print(f"âœ… Autocompleteå–å¾—å®Œäº†: {len(unique_suggestions)}ä»¶")
        return unique_suggestions
    
    async def _get_autocomplete_single(self, client: httpx.AsyncClient, keyword: str, cursor: int) -> List[str]:
        """å˜ä¸€ã‚«ãƒ¼ã‚½ãƒ«ã§Autocompleteã‚’å–å¾—"""
        url = f"{self.base_url}/serp/google/autocomplete/live/advanced"
        
        payload = [{
            "language_code": self.language_code,
            "location_code": self.location_code,
            "keyword": keyword,
            "client": "chrome-omni",
            "cursor_pointer": cursor
        }]
        
        try:
            response = await client.post(url, json=payload, auth=(self.login, self.password))
            response.raise_for_status()
            data = response.json()
            
            if data.get("status_code") == 20000:
                suggestions = []
                print(f"ğŸ” ã‚«ãƒ¼ã‚½ãƒ« {cursor} ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æä¸­...")
                for task in data.get("tasks", []):
                    for result in task.get("result", []):
                        for item in result.get("items", []):
                            suggestion = item.get("suggestion")
                            if suggestion:
                                suggestions.append(suggestion)
                                print(f"   âœ… ã‚µã‚¸ã‚§ã‚¹ãƒˆ: {suggestion}")
                print(f"   ğŸ“Š ã‚«ãƒ¼ã‚½ãƒ« {cursor} ã§ {len(suggestions)}ä»¶å–å¾—")
                return suggestions
            else:
                print(f"âš ï¸ ã‚«ãƒ¼ã‚½ãƒ« {cursor} ã§APIã‚¨ãƒ©ãƒ¼: {data.get('status_message', 'Unknown error')}")
                return []
                
        except Exception as e:
            print(f"âš ï¸ ã‚«ãƒ¼ã‚½ãƒ« {cursor} ã§é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def get_related_searches_and_paa(self, keywords: List[str]) -> Tuple[List[str], List[str]]:
        """è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®Related Searchesã¨People Also Askã‚’ä¸€æ‹¬å–å¾—"""
        print(f"ğŸ” {len(keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAå–å¾—ä¸­...")
        
        url = f"{self.base_url}/serp/google/organic/live/advanced"
        
        # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ä½œæˆ
        payload = [
            {
                "language_code": self.language_code,
                "location_code": self.location_code,
                "keyword": keyword,
                "depth": 2,
                "include_serp_info": True
            }
            for keyword in keywords
        ]
        
        try:
            async with httpx.AsyncClient(timeout=120) as client:
                response = await client.post(url, json=payload, auth=(self.login, self.password))
                response.raise_for_status()
                data = response.json()
                
                all_related_searches = []
                all_paa_questions = []
                
                for task in data.get("tasks", []):
                    if task.get("status_code") == 20000:
                        for result in task.get("result", []):
                            # Related Searchesã®å–å¾—
                            for item in result.get("items", []):
                                if item.get("type") == "related_searches":
                                    if "items" in item and isinstance(item["items"], list):
                                        for rel_item in item["items"]:
                                            if isinstance(rel_item, str):
                                                all_related_searches.append(rel_item)
                                            elif isinstance(rel_item, dict):
                                                suggestion = rel_item.get("text") or rel_item.get("suggestion")
                                                if suggestion:
                                                    all_related_searches.append(suggestion)
                            
                            # People Also Askã®å–å¾—
                            for item in result.get("items", []):
                                if item.get("type") == "people_also_ask":
                                    if "items" in item and isinstance(item["items"], list):
                                        for paa_item in item["items"]:
                                            if isinstance(paa_item, dict):
                                                question = paa_item.get("question")
                                                if question:
                                                    all_paa_questions.append(question)
                
                # é‡è¤‡é™¤å»
                unique_related = list(set(all_related_searches))
                unique_paa = list(set(all_paa_questions))
                
                print(f"âœ… Related Searches + PAAå–å¾—å®Œäº†:")
                print(f"   - Related Searches: {len(unique_related)}ä»¶")
                print(f"   - People Also Ask: {len(unique_paa)}ä»¶")
                
                return unique_related, unique_paa
                
        except Exception as e:
            print(f"âŒ Related Searches + PAAå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return [], []
    
    def analyze_and_select_keywords(self, keywords: List[str], target_count: int = 5) -> List[str]:
        """ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•é¸å®š"""
        print(f"ğŸ¤– {len(keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•åˆ†æãƒ»é¸å®šä¸­...")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        scored_keywords = []
        for keyword in keywords:
            score = 0
            
            # é•·ã•ã‚¹ã‚³ã‚¢ï¼ˆé©åº¦ãªé•·ã•ã‚’å¥½ã‚€ï¼‰
            length = len(keyword)
            if 5 <= length <= 20:
                score += 3
            elif 3 <= length <= 25:
                score += 2
            else:
                score += 1
            
            # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ï¼ˆãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®é–¢é€£æ€§ï¼‰
            main_keywords = ["å¤", "ãŠã™ã™ã‚", "ãŠé…’"]
            relevance_count = sum(1 for main_kw in main_keywords if main_kw in keyword)
            score += relevance_count * 2
            
            # æ¤œç´¢æ„å›³ã‚¹ã‚³ã‚¢
            intent_indicators = ["ãŠã™ã™ã‚", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "æ¯”è¼ƒ", "é¸ã³æ–¹", "é£²ã¿æ–¹", "ä½œã‚Šæ–¹"]
            if any(indicator in keyword for indicator in intent_indicators):
                score += 2
            
            # å­£ç¯€æ€§ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰æ€§ã‚¹ã‚³ã‚¢
            seasonal_terms = ["å¤", "æš‘ã„", "å†·ãŸã„", "ã²ã‚„ãŠã‚ã—"]
            if any(term in keyword for term in seasonal_terms):
                score += 2
            
            # å…·ä½“æ€§ã‚¹ã‚³ã‚¢ï¼ˆå…·ä½“çš„ãªå†…å®¹ã‚’å«ã‚€ï¼‰
            specific_terms = ["ã‚«ã‚¯ãƒ†ãƒ«", "æ—¥æœ¬é…’", "ãƒ“ãƒ¼ãƒ«", "ãƒ¯ã‚¤ãƒ³", "ç„¼é…"]
            if any(term in keyword for term in specific_terms):
                score += 1
            
            scored_keywords.append((keyword, score))
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        scored_keywords.sort(key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸æŠ
        selected = [kw for kw, score in scored_keywords[:target_count]]
        
        print(f"âœ… è‡ªå‹•é¸å®šå®Œäº†: ä¸Šä½{len(selected)}å€‹ã‚’é¸æŠ")
        for i, keyword in enumerate(selected, 1):
            score = next(score for kw, score in scored_keywords if kw == keyword)
            print(f"   {i}. {keyword} (ã‚¹ã‚³ã‚¢: {score})")
        
        return selected
    
    async def collect_suggestions_automated(self, main_keyword: str) -> Dict[str, Any]:
        """å…¨è‡ªå‹•ã§ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã‚’å®Ÿè¡Œ"""
        print(f"ğŸš€ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{main_keyword}ã€ã‹ã‚‰å…¨è‡ªå‹•ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†é–‹å§‹")
        print("=" * 60)
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®Autocompleteå–å¾—
        print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®Autocompleteå–å¾—")
        autocomplete_suggestions = await self.get_autocomplete_batch(main_keyword)
        
        if not autocomplete_suggestions:
            print("âŒ AutocompleteãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return {"error": "Autocompleteå–å¾—å¤±æ•—"}
        
        print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: {len(autocomplete_suggestions)}ä»¶ã®ã‚µã‚¸ã‚§ã‚¹ãƒˆ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: è‡ªå‹•é¸å®š
        print("\nğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹è‡ªå‹•é¸å®š")
        selected_keywords = self.analyze_and_select_keywords(autocomplete_suggestions, target_count=10)
        
        if not selected_keywords:
            print("âŒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
            return {"error": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸å®šå¤±æ•—"}
        
        print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {len(selected_keywords)}å€‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸å®š")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAå–å¾—
        print("\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: é¸å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰Related Searches + PAAå–å¾—")
        related_searches, paa_questions = await self.get_related_searches_and_paa(selected_keywords)
        
        # çµæœã®çµ±åˆ
        all_suggestions = list(set(autocomplete_suggestions + related_searches + paa_questions))
        
        # çµæœã®ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"automated_collected_{main_keyword.replace(' ', '_')}_{len(all_suggestions)}ä»¶.json"
        
        result_data = {
            "main_keyword": main_keyword,
            "collection_method": "å…¨è‡ªå‹•ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰",
            "timestamp": timestamp,
            "api_calls": 2,  # Autocomplete + Related Searches/PAA
            "results": {
                "autocomplete": autocomplete_suggestions,
                "selected_for_expansion": selected_keywords,
                "related_searches": related_searches,
                "people_also_ask": paa_questions,
                "total_unique": len(all_suggestions)
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
        txt_filename = f"automated_collected_{main_keyword.replace(' ', '_')}_{len(all_suggestions)}ä»¶.txt"
        with open(txt_filename, 'w', encoding='utf-8') as f:
            f.write(f"=== å…¨è‡ªå‹•ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†çµæœ ===\n")
            f.write(f"ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {main_keyword}\n")
            f.write(f"åé›†æ–¹æ³•: å…¨è‡ªå‹•ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰\n")
            f.write(f"APIå‘¼ã³å‡ºã—å›æ•°: 2å›\n")
            f.write(f"åé›†æ—¥æ™‚: {timestamp}\n")
            f.write(f"\n")
            f.write(f"=== åé›†çµæœ ===\n")
            f.write(f"ç·ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {len(all_suggestions)}ä»¶\n")
            f.write(f"\n")
            f.write(f"ã€Autocompleteã€‘\n")
            for i, suggestion in enumerate(autocomplete_suggestions, 1):
                f.write(f"{i:2d}. {suggestion}\n")
            f.write(f"\n")
            f.write(f"ã€é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ‹¡å¼µç”¨ï¼‰ã€‘\n")
            for i, keyword in enumerate(selected_keywords, 1):
                f.write(f"{i}. {keyword}\n")
            f.write(f"\n")
            f.write(f"ã€Related Searchesã€‘\n")
            for i, suggestion in enumerate(related_searches, 1):
                f.write(f"{i:2d}. {suggestion}\n")
            f.write(f"\n")
            f.write(f"ã€People Also Askã€‘\n")
            for i, question in enumerate(paa_questions, 1):
                f.write(f"{i:2d}. {question}\n")
            f.write(f"\n")
            f.write(f"ã€å…¨ã‚µã‚¸ã‚§ã‚¹ãƒˆä¸€è¦§ã€‘\n")
            for i, suggestion in enumerate(all_suggestions, 1):
                f.write(f"{i:3d}. {suggestion}\n")
        
        print(f"\nğŸ‰ å…¨è‡ªå‹•ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†å®Œäº†ï¼")
        print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
        print(f"ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {txt_filename}")
        print(f"ğŸ“Š ç·åé›†æ•°: {len(all_suggestions)}ä»¶")
        print(f"ğŸ’° APIå‘¼ã³å‡ºã—å›æ•°: 2å›")
        
        return result_data

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        collector = GoogleSuggestionCollector()
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
        import sys
        if len(sys.argv) > 1:
            main_keyword = " ".join(sys.argv[1:])
        else:
            main_keyword = "å¤ ãŠã™ã™ã‚ ãŠé…’"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        
        print(f"ğŸ¯ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {main_keyword}")
        print("=" * 60)
        
        # å…¨è‡ªå‹•åé›†å®Ÿè¡Œ
        result = await collector.collect_suggestions_automated(main_keyword)
        
        if "error" in result:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result['error']}")
            return 1
        
        print("\nâœ… æ­£å¸¸çµ‚äº†")
        return 0
        
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
