import os
import json
import asyncio
from pathlib import Path
import httpx
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

# Data for SEOè¨­å®š
BASE = os.getenv("DATAFORSEO_BASE", "https://api.dataforseo.com/v3").rstrip("/")
LOGIN = os.getenv("DATAFORSEO_LOGIN")
PASSWORD = os.getenv("DATAFORSEO_PASSWORD")
LANG = os.getenv("DATAFORSEO_LANGUAGE_CODE", "ja")
LOC = int(os.getenv("DATAFORSEO_LOCATION_CODE", "2392"))  # Japan

class AgentOptimizedGoogleCollector:
    def __init__(self):
        self.client = None
        self.all_keywords = set()
        
    async def __aenter__(self):
        self.client = httpx.AsyncClient(
            auth=(LOGIN, PASSWORD),
            headers={"Content-Type": "application/json"},
            timeout=60
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.client:
            await self.client.aclose()
    
    async def check_connection(self):
        """æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            r = await self.client.get(f"{BASE}/appendix/user_data", timeout=30)
            j = r.json()
            if j.get("status_code") == 20000:
                print("âœ… Data for SEOæ¥ç¶šæˆåŠŸ")
                return True
            else:
                print(f"âŒ æ¥ç¶šå¤±æ•—: {j.get('status_message')}")
                return False
        except Exception as e:
            print(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def analyze_and_select_keywords(self, base_keywords, target_count=15):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ»é¸å®š"""
        print(f"ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ»é¸å®šä¸­...")
        print(f"   å¯¾è±¡: {len(base_keywords)}ä»¶ â†’ é¸å®šç›®æ¨™: {target_count}ä»¶")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è³ªã‚’åˆ†æ
        keyword_scores = {}
        
        for kw in base_keywords:
            score = 0
            
            # 1. é•·ã•ã‚¹ã‚³ã‚¢ï¼ˆé©åº¦ãªé•·ã•ã‚’è©•ä¾¡ï¼‰
            if 3 <= len(kw) <= 15:
                score += 3
            elif 15 < len(kw) <= 25:
                score += 2
            else:
                score += 1
            
            # 2. å…·ä½“æ€§ã‚¹ã‚³ã‚¢ï¼ˆå…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è©•ä¾¡ï¼‰
            specific_indicators = ['ã¨ã¯', 'æ–¹æ³•', 'ã‚„ã‚Šæ–¹', 'ãŠã™ã™ã‚', 'æ¯”è¼ƒ', 'åŠ¹æœ', 'æ–™é‡‘', 'æ™‚é–“']
            for indicator in specific_indicators:
                if indicator in kw:
                    score += 2
                    break
            
            # 3. æ¤œç´¢æ„å›³ã‚¹ã‚³ã‚¢ï¼ˆæ¤œç´¢æ„å›³ãŒæ˜ç¢ºãªã‚‚ã®ã‚’è©•ä¾¡ï¼‰
            intent_indicators = ['ãƒ†ã‚¹ãƒˆ', 'æ–¹æ³•', 'ã‚„ã‚Šæ–¹', 'ãŠã™ã™ã‚', 'æ¯”è¼ƒ', 'åŠ¹æœ', 'æ–™é‡‘']
            for indicator in intent_indicators:
                if indicator in kw:
                    score += 1
            
            # 4. é‡è¤‡åº¦ã‚¹ã‚³ã‚¢ï¼ˆé‡è¤‡ã®å°‘ãªã„ã‚‚ã®ã‚’è©•ä¾¡ï¼‰
            words = kw.split()
            unique_words = len(set(words))
            if unique_words >= 3:
                score += 2
            elif unique_words == 2:
                score += 1
            
            keyword_scores[kw] = score
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸æŠ
        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
        selected_keywords = [kw for kw, score in sorted_keywords[:target_count]]
        
        print(f"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸å®šå®Œäº†: {len(selected_keywords)}ä»¶ã‚’é¸æŠ")
        print(f"   é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:")
        for i, kw in enumerate(selected_keywords, 1):
            score = keyword_scores[kw]
            print(f"     {i:2d}. {kw} (ã‚¹ã‚³ã‚¢: {score})")
        
        return selected_keywords
    
    async def get_autocomplete_single(self, keyword, cursor):
        """å˜ä¸€ã‚«ãƒ¼ã‚½ãƒ«ã§ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—"""
        task = {
            "language_code": LANG,
            "location_code": LOC,
            "keyword": keyword,
            "client": "chrome",
            "cursor_pointer": cursor
        }
        
        try:
            r = await self.client.post(
                f"{BASE}/serp/google/autocomplete/live/advanced",
                json=[task]
            )
            j = r.json()
            
            suggestions = []
            for t in j.get("tasks", []):
                for res in t.get("result", []):
                    for item in res.get("items", []):
                        if item.get("type") == "autocomplete":
                            suggestion = item.get("suggestion") or item.get("text") or item.get("value")
                            if suggestion:
                                suggestions.append(suggestion)
            
            return suggestions
            
        except Exception as e:
            print(f"    âš ï¸ ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼ ({keyword}): {e}")
            return []
    
    async def get_autocomplete_parallel(self, keyword, cursors):
        """è¤‡æ•°ã‚«ãƒ¼ã‚½ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ã§ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—"""
        print(f"ğŸš€ ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã‹ã‚‰{len(cursors)}å€‹ã®ã‚«ãƒ¼ã‚½ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ä¸­...")
        
        # ä¸¦åˆ—å‡¦ç†ã§è¤‡æ•°ã‚«ãƒ¼ã‚½ãƒ«ã‚’åŒæ™‚å®Ÿè¡Œ
        tasks = [self.get_autocomplete_single(keyword, cursor) for cursor in cursors]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_suggestions = []
        for i, result in enumerate(results):
            if isinstance(result, list):
                all_suggestions.extend(result)
                print(f"  ğŸ“ ã‚«ãƒ¼ã‚½ãƒ« {cursors[i]}: {len(result)}ä»¶å–å¾—")
            else:
                print(f"  âš ï¸ ã‚«ãƒ¼ã‚½ãƒ« {cursors[i]}: ã‚¨ãƒ©ãƒ¼")
        
        # é‡è¤‡é™¤å»
        unique_suggestions = list(dict.fromkeys(all_suggestions))
        self.all_keywords.update(unique_suggestions)
        
        print(f"âœ… ä¸¦åˆ—å‡¦ç†å®Œäº†: {len(unique_suggestions)}ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        return unique_suggestions
    
    async def expand_selected_keywords(self, selected_keywords, max_per_keyword=4):
        """é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰åŠ¹ç‡çš„ã«æ‹¡å¼µ"""
        print(f"ğŸ” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{len(selected_keywords)}ä»¶ã‹ã‚‰åŠ¹ç‡çš„ã«æ‹¡å¼µä¸­...")
        print(f"   âš¡ å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æœ€å¤§{max_per_keyword}ä»¶ãšã¤å–å¾—")
        
        # ä¸¦åˆ—å®Ÿè¡Œï¼ˆåŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™ï¼‰
        semaphore = asyncio.Semaphore(5)  # åŒæ™‚å®Ÿè¡Œæ•°ã‚’5ã«åˆ¶é™
        
        async def expand_single_keyword(kw):
            async with semaphore:
                suggestions = await self.get_autocomplete_single(kw, 0)
                return suggestions[:max_per_keyword]
        
        tasks = [expand_single_keyword(kw) for kw in selected_keywords]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        new_suggestions = []
        for i, result in enumerate(results):
            if isinstance(result, list):
                for suggestion in result:
                    if suggestion not in self.all_keywords:
                        new_suggestions.append(suggestion)
                        self.all_keywords.add(suggestion)
                print(f"  ğŸ“ {selected_keywords[i]}: {len(result)}ä»¶å–å¾—")
            else:
                print(f"  âš ï¸ {selected_keywords[i]}: ã‚¨ãƒ©ãƒ¼")
        
        print(f"âœ… æ‹¡å¼µå–å¾—å®Œäº†: {len(new_suggestions)}ä»¶ã®æ–°è¦ã‚µã‚¸ã‚§ã‚¹ãƒˆ")
        return new_suggestions
    
    async def run_agent_optimized_collection(self, seed_keyword, target_count=100):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–ã«ã‚ˆã‚‹ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†"""
        print(f"ğŸš€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–Googleã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†é–‹å§‹: ã€Œ{seed_keyword}ã€")
        print(f"ğŸ¯ ç›®æ¨™: {target_count}ä»¶")
        print(f"ğŸ’¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒäº‹å‰åˆ†æã—ã¦åŠ¹ç‡çš„ã«æ‹¡å¼µ")
        
        # æ¥ç¶šç¢ºèª
        if not await self.check_connection():
            return None
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ä¸¦åˆ—ã§ã‚µã‚¸ã‚§ã‚¹ãƒˆå–å¾—
        efficient_cursors = [0, 1, 2, 3]  # 0-3ã®4å€‹
        base_suggestions = await self.get_autocomplete_parallel(seed_keyword, efficient_cursors)
        
        print(f"\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1çµæœ: {len(base_suggestions)}ä»¶ã®ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸å®š
        selected_keywords = self.analyze_and_select_keywords(base_suggestions, target_count=15)
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: é¸å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰åŠ¹ç‡çš„ã«æ‹¡å¼µ
        if len(selected_keywords) > 0:
            expanded_suggestions = await self.expand_selected_keywords(selected_keywords, max_per_keyword=4)
        else:
            expanded_suggestions = []
        
        # æœ€çµ‚çµæœ
        final_keywords = list(self.all_keywords)[:target_count]
        
        # ã‚³ã‚¹ãƒˆè¨ˆç®—
        total_api_calls = len(efficient_cursors) + len(selected_keywords)
        estimated_cost = total_api_calls * 0.02  # $0.02/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        
        print(f"\nğŸ‰ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ€é©åŒ–åé›†å®Œäº†!")
        print(f"ğŸ“Š æœ€çµ‚çµæœ: {len(final_keywords)}ä»¶")
        print(f"   - ãƒ™ãƒ¼ã‚¹ã‚µã‚¸ã‚§ã‚¹ãƒˆ: {len(base_suggestions)}ä»¶")
        print(f"   - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé¸å®š: {len(selected_keywords)}ä»¶")
        print(f"   - æ‹¡å¼µã‚µã‚¸ã‚§ã‚¹ãƒˆ: {len(expanded_suggestions)}ä»¶")
        print(f"   - ç·ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {len(self.all_keywords)}ä»¶")
        print(f"ğŸ’° ã‚³ã‚¹ãƒˆåˆ†æ:")
        print(f"   - APIå‘¼ã³å‡ºã—å›æ•°: {total_api_calls}å›")
        print(f"   - æ¨å®šã‚³ã‚¹ãƒˆ: ${estimated_cost:.2f} (ç´„{estimated_cost*150:.0f}å††)")
        print(f"   - å¾“æ¥æ–¹å¼ã¨ã®æ¯”è¼ƒ: ç´„{(1 - len(selected_keywords)/len(base_suggestions))*100:.0f}%ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›")
        
        return {
            "seed": seed_keyword,
            "total_collected": len(final_keywords),
            "keywords": final_keywords,
            "raw_data": {
                "base_suggestions": base_suggestions,
                "selected_keywords": selected_keywords,
                "expanded_suggestions": expanded_suggestions
            },
            "cost_analysis": {
                "total_api_calls": total_api_calls,
                "estimated_cost_usd": estimated_cost,
                "estimated_cost_jpy": estimated_cost * 150,
                "cost_reduction_percent": (1 - len(selected_keywords)/len(base_suggestions))*100
            },
            "breakdown": {
                "base_suggestions": len(base_suggestions),
                "selected_keywords": len(selected_keywords),
                "expanded_suggestions": len(expanded_suggestions),
                "total_unique": len(self.all_keywords)
            }
        }

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if not LOGIN or not PASSWORD:
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—
    import sys
    seed_keyword = sys.argv[1] if len(sys.argv) > 1 else "ãƒ†ã‚¹ãƒˆ"
    target_count = int(sys.argv[2]) if len(sys.argv) > 2 else 100
    
    print(f"ğŸŒ± ã‚·ãƒ¼ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {seed_keyword}")
    print(f"ğŸ¯ ç›®æ¨™ä»¶æ•°: {target_count}ä»¶")
    
    async with AgentOptimizedGoogleCollector() as collector:
        result = await collector.run_agent_optimized_collection(seed_keyword, target_count)
        
        if result:
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_file = f"agent_optimized_{seed_keyword}_{len(result['keywords'])}ä»¶.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ä¸Šä½30ä»¶ã‚’è¡¨ç¤º
            print(f"\nğŸ“‹ ä¸Šä½30ä»¶:")
            for i, kw in enumerate(result['keywords'][:30], 1):
                print(f"  {i:2d}. {kw}")

if __name__ == "__main__":
    asyncio.run(main())
