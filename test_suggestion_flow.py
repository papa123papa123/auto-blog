#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã‹ã‚‰ã‚µãƒ–KWæ±ºå®šã¾ã§ã®å‡¦ç†ã®æµã‚Œã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import json
import os
from pathlib import Path
from datetime import datetime

def test_suggestion_collection_flow():
    """ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã®æµã‚Œã‚’ãƒ†ã‚¹ãƒˆ"""
    print("=== ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ ===")
    
    # 1. collect_google_suggestions_ä¿è­·æ¸ˆã¿_çµ¶å¯¾å¤‰æ›´ç¦æ­¢.pyã®å‹•ä½œç¢ºèª
    print("\n1. SERPã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ãƒ†ã‚¹ãƒˆ")
    try:
        from collect_google_suggestions_ä¿è­·æ¸ˆã¿_çµ¶å¯¾å¤‰æ›´ç¦æ­¢ import SERPCollector
        
        async def test_serp_collection():
            collector = SERPCollector()
            main_keyword = "å¤ ãŠé…’ ãŠã™ã™ã‚"
            result = await collector.collect_suggestions(main_keyword)
            
            if result:
                # ä¿å­˜å ´æ‰€ã‚’serp_results/raw_data/ã«å¤‰æ›´
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"serp_results/raw_data/serp_collected_{len(result['results']['suggestions'])}ä»¶.json"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… SERPåé›†å®Œäº†: {len(result['results']['suggestions'])}ä»¶")
                print(f"ğŸ“ ä¿å­˜å ´æ‰€: {filename}")
                return result
            else:
                print("âŒ SERPåé›†ã«å¤±æ•—")
                return None
        
        result = asyncio.run(test_serp_collection())
        
    except Exception as e:
        print(f"âŒ SERPåé›†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    # 2. extract_seo_content.pyã®å‹•ä½œç¢ºèª
    print("\n2. SEOã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    try:
        from extract_seo_content import extract_seo_content
        
        if result:
            # ä¿å­˜å ´æ‰€ã‚’serp_results/extracted_content/ã«å¤‰æ›´
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            content_filename = f"serp_results/extracted_content/seo_content_{len(result['results']['suggestions'])}ä»¶.txt"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
            all_content = extract_seo_content(result)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(content_filename, 'w', encoding='utf-8') as f:
                f.write(f"=== SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºçµæœ ===\n")
                f.write(f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«: serp_collected_{len(result['results']['suggestions'])}ä»¶.json\n")
                f.write(f"æŠ½å‡ºä»¶æ•°: {len(all_content)}ä»¶\n")
                f.write(f"æŠ½å‡ºæ—¥æ™‚: {timestamp}\n")
                f.write("=" * 50 + "\n\n")
                for i, content in enumerate(all_content, 1):
                    f.write(f"{i}. {content}\n")
            
            print(f"âœ… SEOã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºå®Œäº†: {len(all_content)}ä»¶")
            print(f"ğŸ“ ä¿å­˜å ´æ‰€: {content_filename}")
            
    except Exception as e:
        print(f"âŒ SEOã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. extract_seo_keywords.pyã®å‹•ä½œç¢ºèª
    print("\n3. SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    try:
        from extract_seo_keywords import extract_all_content_for_seo
        
        if result:
            # ä¿å­˜å ´æ‰€ã‚’serp_results/final_keywords/ã«å¤‰æ›´
            keywords_filename = f"serp_results/final_keywords/seo_all_content_{len(result['results']['suggestions'])}ä»¶.txt"
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            all_keywords = extract_all_content_for_seo(result)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(keywords_filename, 'w', encoding='utf-8') as f:
                f.write(f"=== SEOç”¨å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœ ===\n")
                f.write(f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«: serp_collected_{len(result['results']['suggestions'])}ä»¶.json\n")
                f.write(f"æŠ½å‡ºä»¶æ•°: {len(all_keywords)}ä»¶\n")
                f.write(f"æŠ½å‡ºæ—¥æ™‚: {timestamp}\n")
                f.write("=" * 50 + "\n\n")
                for i, keyword in enumerate(all_keywords, 1):
                    f.write(f"{i}. {keyword}\n")
            
            print(f"âœ… SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºå®Œäº†: {len(all_keywords)}ä»¶")
            print(f"ğŸ“ ä¿å­˜å ´æ‰€: {keywords_filename}")
            
    except Exception as e:
        print(f"âŒ SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ã‚µãƒ–KWæ±ºå®šã®ãƒ†ã‚¹ãƒˆ
    print("\n4. ã‚µãƒ–KWæ±ºå®šãƒ†ã‚¹ãƒˆ")
    try:
        # ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰1ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
        print("ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰1ã§ã¯ã€strategic_keyword_flow.pyå†…ã®å‡¦ç†ã‚’ä½¿ç”¨")
        print("ã“ã®éƒ¨åˆ†ã¯æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã§å‹•ä½œç¢ºèªæ¸ˆã¿")
        
    except Exception as e:
        print(f"âŒ ã‚µãƒ–KWæ±ºå®šã§ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª
    print("\n=== ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª ===")
    serp_dirs = ["serp_results", "serp_results/raw_data", "serp_results/extracted_content", "serp_results/final_keywords"]
    for dir_path in serp_dirs:
        if Path(dir_path).exists():
            print(f"âœ… {dir_path}")
        else:
            print(f"âŒ {dir_path}")
    
    # ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_suggestion_collection_flow()
    
    print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    print("çµæœã‚’ç¢ºèªã—ã¦ã€å‡¦ç†ã®æµã‚ŒãŒæ­£ã—ã„ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
