# src/haru_system.py

import os
from typing import Dict, List
from pathlib import Path
import datetime
import json
import re
from dotenv import load_dotenv

from src.gemini_generator import GeminiGenerator
from src.serp_analyzer import SerpAnalyzer
from src.content_extractor import ContentExtractor
from src.prompt_manager import PromptManager
from src.wordpress_connector import WordPressConnector
from src.image_processor import ImageProcessor
from src.site_manager import SiteManager
from src.keyword_suggester import KeywordSuggester
from src.keyword_hunter import KeywordHunter
from src.sub_keyword_selector import SubKeywordSelector
from src.keyword_analyzer import KeywordAnalyzer
from src.spec_extractor import SpecExtractor
from src.flows.full_article_generation_flow import FullArticleGenerationFlow
from src.flows.database_construction_flow import DatabaseConstructionFlow
from src.flows.strategic_keyword_flow import StrategicKeywordFlow
from src.flows.manual_content_flow import ManualContentFlow

class HaruOrchestrator:
    def __init__(self):
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        serp_api_key = os.getenv("SERPAPI_API_KEY")
        gcp_project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")

        if not all([gemini_api_key, serp_api_key, gcp_project_id]):
            raise ValueError(".envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEY, SERPAPI_API_KEY, GOOGLE_CLOUD_PROJECT_IDã®ã„ãšã‚Œã‹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        print("å¸ä»¤å¡”ãŒå…¨ã¦ã®å°‚é–€å®¶ã‚’æº–å‚™ä¸­...")
        
        self.gemini_generator = GeminiGenerator()
        self.image_processor = ImageProcessor()
        self.serp_analyzer = SerpAnalyzer(api_key=serp_api_key)
        self.keyword_suggester = KeywordSuggester()
        self.content_extractor = ContentExtractor()
        self.prompt_manager = PromptManager()
        self.wordpress_connector = WordPressConnector()
        self.site_manager = SiteManager()
        self.keyword_analyzer = KeywordAnalyzer(serp_analyzer=self.serp_analyzer)
        self.spec_extractor = SpecExtractor(gemini_generator=self.gemini_generator)
        
        self.keyword_hunter = KeywordHunter(
            serp_analyzer=self.serp_analyzer,
            keyword_suggester=self.keyword_suggester
        )
        self.sub_keyword_selector = SubKeywordSelector(
            gemini_generator=self.gemini_generator,
            prompt_manager=self.prompt_manager
        )
        
        self.database_construction_flow = DatabaseConstructionFlow(
            serp_analyzer=self.serp_analyzer,
            gemini_generator=self.gemini_generator,
            prompt_manager=self.prompt_manager,
            content_extractor=self.content_extractor
        )
        self.full_article_generation_flow = FullArticleGenerationFlow(
            gemini_generator=self.gemini_generator,
            prompt_manager=self.prompt_manager,
            image_processor=self.image_processor
        )
        self.strategic_keyword_flow = StrategicKeywordFlow(
            keyword_hunter=self.keyword_hunter,
            sub_keyword_selector=self.sub_keyword_selector
        )
        self.manual_content_flow = ManualContentFlow(
            spec_extractor=self.spec_extractor,
            sub_keyword_selector=self.sub_keyword_selector,
            gemini_generator=self.gemini_generator
        )
        print("[OK] å…¨ã¦ã®å°‚é–€å®¶ã¨ãƒ•ãƒ­ãƒ¼ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    def run_manual_content_flow(self):
        return self.manual_content_flow.run()

    def run_strategic_keyword_flow(self, auto_yes: bool = False):
        """
        ã€æ”¹ä¿®å¾Œã€‘æˆ¦ç•¥çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã€ãƒ¡ã‚¤ãƒ³KWã¨æ§‹æˆæ¡ˆJSONã‚’è¿”ã™ã€‚
        """
        # strategic_keyword_flow.run()ãŒã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åé›†ã‹ã‚‰æ§‹æˆæ¡ˆä½œæˆã¾ã§å…¨ã¦å®Ÿè¡Œã—ã€
        # main_keywordã¨article_structureã‚’è¿”ã™ã‚ˆã†ã«ãªã£ãŸã€‚
        main_keyword, article_structure = self.strategic_keyword_flow.run(auto_yes)
        return main_keyword, article_structure

    def run_keyword_research_flow(self):
        print("\n--- [è¶…é«˜é€Ÿ] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹ãƒ»åˆ†æãƒ•ãƒ­ãƒ¼ ---")
        self.keyword_analyzer.run_analysis()

    def run_full_article_creation_flow(self, site_info: Dict, credentials: Dict):
        """
        ã€æœ€çµ‚ç‰ˆã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸å®šã‹ã‚‰è¨˜äº‹ç”Ÿæˆã€æŠ•ç¨¿ã¾ã§ã‚’ä¸€æ°—é€šè²«ã§å®Ÿè¡Œã™ã‚‹ãƒ•ãƒ­ãƒ¼ã€‚
        """
        # 1. ã€æ”¹ä¿®ã€‘æˆ¦ç•¥çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸å®šï¼†æ§‹æˆæ¡ˆä½œæˆ
        main_keyword, article_structure = self.run_strategic_keyword_flow()
        if not (main_keyword and article_structure):
            print("\næ§‹æˆæ¡ˆã®ä½œæˆãŒæ­£å¸¸ã«å®Œäº†ã—ãªã‹ã£ãŸãŸã‚ã€ãƒ•ãƒ­ãƒ¼ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return

        # 2. ã€æ–°è¦è¿½åŠ ã€‘collect_google_suggestions.py + extract_seo_content.pyã‚’ä½¿ç”¨ã—ã¦ã‚µã‚¸ã‚§ã‚¹ãƒˆå¤šæ•°å–å¾—
        print("\n--- ã‚¹ãƒ†ãƒƒãƒ—2: Googleã‚µã‚¸ã‚§ã‚¹ãƒˆåé›† â†’ SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º ---")
        try:
            # 1. ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†
            print("ğŸ“Š Google SERP API ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ä¸­...")
            import subprocess
            import sys
            
            result1 = subprocess.run([sys.executable, "collect_google_suggestions.py"], 
                                   capture_output=True, text=True, encoding='utf-8')
            
            if result1.returncode == 0:
                print("âœ… ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                if result1.stdout:
                    print(result1.stdout)
            else:
                print(f"âŒ ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ãŒå¤±æ•—ã—ã¾ã—ãŸ: {result1.stderr}")
                print("æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
                collected_suggestions = []
            
            # 2. SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
            print("ğŸ” SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºä¸­...")
            result2 = subprocess.run([sys.executable, "extract_seo_content.py"], 
                                   capture_output=True, text=True, encoding='utf-8')
            
            if result2.returncode == 0:
                print("âœ… SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸ")
                if result2.stdout:
                    print(result2.stdout)
            else:
                print(f"âŒ SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãŒå¤±æ•—ã—ã¾ã—ãŸ: {result2.stderr}")
                print("æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
                collected_suggestions = []
            
            # 3. æŠ½å‡ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã¿
            import glob
            seo_files = glob.glob("seo_results/seo_content_*.txt")
            if seo_files:
                # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                latest_file = max(seo_files, key=os.path.getctime)
                with open(latest_file, 'r', encoding='utf-8') as f:
                    content_lines = f.readlines()
                
                # ç•ªå·ã‚’é™¤å»ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã¿ã‚’æŠ½å‡º
                collected_suggestions = []
                for line in content_lines:
                    if line.strip() and '. ' in line:
                        content = line.split('. ', 1)[1].strip()
                        if content:
                            collected_suggestions.append(content)
                
                print(f"âœ… SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„èª­ã¿è¾¼ã¿å®Œäº†: {len(collected_suggestions)}ä»¶")
                print(f"ğŸ“ èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
            else:
                print("âš ï¸ SEOç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
                collected_suggestions = []
                
        except Exception as e:
            print(f"âš ï¸ ã‚µã‚¸ã‚§ã‚¹ãƒˆåé›†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
            collected_suggestions = []

        # 3. é«˜å“è³ªJSONãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰
        # æ§‹æˆæ¡ˆã‹ã‚‰H3ãƒªã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦æ¸¡ã™
        sub_keywords = [h3 for h2 in article_structure.get("outline", []) for h3 in h2.get("h3", [])]
        final_json_database = self.database_construction_flow.build_database_from_sub_keywords(main_keyword, sub_keywords)
        if not (final_json_database and final_json_database.strip()):
            print("[NG] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ã«å¤±æ•—ã€ã¾ãŸã¯åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ãƒ•ãƒ­ãƒ¼ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return

        # 4. è¨˜äº‹ã¨ç”»åƒã®ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆï¼ˆå®Œå…¨ä¸¦åˆ—ï¼‰
        success = self.full_article_generation_flow.run(main_keyword, article_structure, final_json_database)
        if not success:
            print("[NG] è¨˜äº‹ã¨ç”»åƒã®ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return
            
        # 5. è‡ªå‹•æŠ•ç¨¿
        self._post_from_cache(site_info, credentials)

    def _post_from_cache(self, site_info: Dict, credentials: Dict):
        """ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¨˜äº‹ã¨ç”»åƒã‚’æŠ•ç¨¿ã™ã‚‹å†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        print("\n--- WordPressã¸ã®è‡ªå‹•æŠ•ç¨¿ã‚¹ãƒ†ãƒƒãƒ— ---")
        if not Path("article_cache.md").exists() or not Path("image_prompts.json").exists():
            print("[ã‚¨ãƒ©ãƒ¼] æŠ•ç¨¿ã«å¿…è¦ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        result = self.wordpress_connector.post_from_cache(site_info, credentials)
        if result.get("success"):
            print(f"\n[æˆåŠŸ] æŠ•ç¨¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼ URL: {result.get('link')}")
            self.site_manager.update_article_count(site_info['id'])
        else:
            print(f"\n[å¤±æ•—] æŠ•ç¨¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result.get('error')}")